{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n在pytorch tutorial的某个例子的基础上作了改动，可以运行，可以作为参考\\n暂时还是用的例子里面的gru和attention方式,已经实现了bidirectional\\n正在尝试改为LSTM\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "在pytorch tutorial的某个例子的基础上作了改动，可以运行，可以作为参考\n",
    "暂时还是用的例子里面的gru和attention方式,已经实现了bidirectional\n",
    "正在尝试改为LSTM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 包导入与常量定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import numpy \n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = \"./rnnpg_data_emnlp-2014/partitions_in_Table_2/rnnpg/\"  #到数据集的路径，可能根据具体情况修改\n",
    "root_path=\"\"\n",
    "BATCH_SIZE=128\n",
    "LEN = 7 # 用于决定5言还是7言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6774\n",
      "2447\n",
      "水\n"
     ]
    }
   ],
   "source": [
    "with open('word_vocab.pkl', 'rb') as f:\n",
    "     vocab = pickle.load(f)\n",
    "wd2Idx = {wd: idx for idx, wd in enumerate(vocab)}\n",
    "idx2Wd = {idx: wd for idx, wd in enumerate(vocab)}\n",
    "print(len(vocab))\n",
    "print(wd2Idx['水']) \n",
    "print(idx2Wd[2447])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1511, 5062, 4094, 772, 2985, 895, 6343, 1762, 3274, 5734, 3767, 3091, 6419, 2521, 5205, 370, 4524, 261, 3732, 3184, 2377, 6074]\n"
     ]
    }
   ],
   "source": [
    "def get_train_data(fileName, wd2Idx ):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        fileName:文件名，具体应该为\"qtrain\"\n",
    "\n",
    "    @return:\n",
    "        poem_line_lst5:五言绝句列表\n",
    "        poem_line_lst7:七言绝句列表\n",
    "        poem_vec_lst5:映射后的五言绝句列表\n",
    "        poem_vec_lst7:映射后的七言绝句列表\n",
    "    \n",
    "    其它:\n",
    "        暂时没有为每句诗加上<S>和<E>\n",
    "    \"\"\"\n",
    "    poem_line_lst5 = []\n",
    "    poem_line_lst7 = []\n",
    "\n",
    "    poem_vec_lst5 = []\n",
    "    poem_vec_lst7 = []\n",
    "\n",
    "    \n",
    "\n",
    "    with open(root_path + fileName, 'r', encoding='utf-8') as fin:\n",
    "        for line in fin:\n",
    "            line = (\" \".join(line.strip().split(\"\\t\"))).split(\" \")\n",
    "            line = [\"<S>\"] + line + [\"<E>\"]\n",
    "            if len(line) == 22:\n",
    "                poem_line_lst5.append(line)\n",
    "               \n",
    "            elif len(line) == 30:\n",
    "                poem_line_lst7.append(line)\n",
    "                \n",
    "\n",
    "    random.shuffle(poem_line_lst5)\n",
    "    random.shuffle(poem_line_lst7)\n",
    "\n",
    "    poem_vec_lst5 = [[wd2Idx[wd] for wd in line] for line in poem_line_lst5]\n",
    "    poem_vec_lst7 = [[wd2Idx[wd] for wd in line] for line in poem_line_lst7]\n",
    "\n",
    "    \n",
    "\n",
    "    return poem_line_lst5, poem_line_lst7,poem_vec_lst5, poem_vec_lst7\n",
    "\n",
    "\n",
    "poem_line_lst5, poem_line_lst7, poem_vec_lst5, poem_vec_lst7 = get_train_data( \n",
    "    \"qtrain\", wd2Idx)\n",
    "print(poem_vec_lst5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data,bat,sent_len):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        data:待划分的数据集\n",
    "        bat:BATCH_SIZE\n",
    "        sent_len:单句长度\n",
    "    \n",
    "    @returns:\n",
    "        X_batch:shape: len(data)//bat,bat,seq_len,其中seq_len包含四句诗\n",
    "        Y_batch:shape: len(data)//bat,bat,seq_len,其中seq_len包含后三句诗\n",
    "    \"\"\"\n",
    "    X_batch = []\n",
    "    Y_batch = []\n",
    "    for idx in range(len(data)//bat):\n",
    "        st = idx * bat\n",
    "        ed = st + bat\n",
    "        X_batch.append([vec[:sent_len] for vec in data[st:ed]])\n",
    "        Y_batch.append([vec[sent_len:] for vec in data[st:ed]])\n",
    "    X_batch = torch.tensor(X_batch,device=device)\n",
    "    Y_batch = torch.tensor(Y_batch,device=device)\n",
    "    \n",
    "    return X_batch,Y_batch\n",
    "\n",
    "X_batch,Y_batch = get_batch(poem_vec_lst7,BATCH_SIZE,LEN+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([496, 128, 8])\n",
      "496\n"
     ]
    }
   ],
   "source": [
    "print(X_batch.shape)\n",
    "print(X_batch.size(0))\n",
    "# print(X_batch[0].permute(1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入预训练的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_net = nn.Sequential(nn.Embedding(len(vocab), 200),\n",
    "                         nn.Embedding(len(vocab), 200))\n",
    "word_vec_net.load_state_dict(torch.load(\"word_vector.pth\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,vec_dim,num_layer):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vec_dim = vec_dim\n",
    "        self.embedding = nn.Embedding(input_size,vec_dim)\n",
    "        self.gru = nn.GRU(vec_dim,hidden_size,num_layers=num_layer,bidirectional=True)\n",
    "        self.num_layer = num_layer\n",
    "        self.num_dir = 1 if self.gru.bidirectional == False else 2\n",
    "\n",
    "    def forward(self,input,hidden):\n",
    "        \"\"\"\n",
    "        @params:\n",
    "            input:(seq_len,batch)\n",
    "            hidden:(num_layers*num_dirs,batch,hidden_size)\n",
    "        \"\"\"\n",
    "        seq_len,batch = input.size()\n",
    "\n",
    "        embedded = self.embedding(input).view(seq_len,batch,-1) \n",
    "        output = embedded  # output:(seq_len,batch,vec_dim)\n",
    "        output,hidden = self.gru(output,hidden) # output:(seq_len,batch,num_dir*hidden_size)\n",
    "                                                # hidden:(num_layer*num_dir,batch,hidden_size)\n",
    "        output = output[:,:,:self.hidden_size]+output[:,:,self.hidden_size:]\n",
    "        hidden = hidden.view(self.num_layer,self.num_dir,batch,self.hidden_size)\n",
    "        hidden = hidden[:,0,:,:] + hidden[:,1,:,:]\n",
    "        # output:seq_len,batch,hidden_size\n",
    "        # hidden:num_layer,batch,hidden_size\n",
    "        return output,hidden\n",
    "\n",
    "    def initHidden(self,bat):\n",
    "        \"\"\"\n",
    "        @params\n",
    "            bat:batch参数\n",
    "        \"\"\"\n",
    "        return torch.zeros(self.num_layer*self.num_dir, bat, self.hidden_size, device=device)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带attention机制的Decoder模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,vec_dim,num_layer,dropout_p):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vec_dim = vec_dim\n",
    "        self.embedding = nn.Embedding(input_size,vec_dim)\n",
    "        self.encode_seq_len = LEN+1\n",
    "        self.dropout_p = dropout_p\n",
    "        self.input_size = input_size\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "        self.gru = nn.GRU(vec_dim,hidden_size,num_layers=num_layer,bidirectional=False)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.vec_dim,self.encode_seq_len)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+self.vec_dim,self.vec_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.out = nn.Linear(self.hidden_size,self.input_size)\n",
    "\n",
    "        self.num_dir = 1 if self.gru.bidirectional == False else 2\n",
    "\n",
    "    def forward(self,input,hidden,encoder_outputs):\n",
    "        \"\"\"\n",
    "        @params:\n",
    "            encoder_outputs:encode_seq_len,batch,num_dir*hidden_size\n",
    "            hidden:num_layer*num_dir,batch,hidden_size\n",
    "            input:seq_len,batch\n",
    "        \"\"\"\n",
    "        seq_len,batch = input.size()  # when decoding ,we let seq_len = 1\n",
    "\n",
    "        embedded = self.embedding(input).view(seq_len,batch,-1)\n",
    "        embedded = self.dropout(embedded)      # embedded:1,batch,vec_dim\n",
    "\n",
    "        attn_weights = F.softmax(              # attn_weights:batch,encode_seq_len\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                encoder_outputs.permute(1,0,2).contiguous()) \n",
    "        # so far,shape of attn_applied:batch,1,hidden_size\n",
    "        attn_applied = attn_applied.permute(1,0,2).contiguous()\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        # output:1,batch,vec_dim\n",
    "        output,hidden = self.gru(output,hidden)\n",
    "        # output:1,batch,vec_dim\n",
    "        logits = self.out(output)  # logits:1,batch,input_size\n",
    "        logits = logits.view(-1,self.input_size)\n",
    "        \n",
    "        return logits,hidden,attn_weights\n",
    "    \n",
    "    def initHidden(self,bat):\n",
    "        return torch.zeros(self.num_dir * self.num_layer, bat, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor,target_tensor,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion,wd2Idx):\n",
    "    \"\"\"\n",
    "    @params\n",
    "        input_tensor:batch,seq_len\n",
    "    \"\"\"\n",
    "\n",
    "    input_tensor = input_tensor.permute(1,0).contiguous()\n",
    "    target_tensor = target_tensor.permute(1,0).contiguous()\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(input_tensor.size()[1])\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_len = input_tensor.size(0)\n",
    "    target_len = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs =  torch.zeros(LEN+1,encoder.hidden_size,device = device) # 单向、batch=1\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs,encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "    # encoder_outputs:encode_seq_len,batch,num_dir*hidden_size\n",
    "    # encoder_hidden:num_layer*num_dir,batch,hidden_size\n",
    "    \n",
    "    decoder_input = torch.tensor([wd2Idx[\"<S>\"]]*BATCH_SIZE,device=device).view(1,BATCH_SIZE)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Teacher forcing\n",
    "    for di in range(target_len):\n",
    "        decoder_output,decoder_hidden,decoder_attention = decoder(\n",
    "            decoder_input,decoder_hidden,encoder_outputs\n",
    "        )\n",
    "        loss += criterion(decoder_output,target_tensor[di])\n",
    "        decoder_input = target_tensor[di].view(1,-1)\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()/target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainIters 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, wd2Idx,epoch,print_every=100, plot_every=100, learning_rate=0.005):\n",
    "\n",
    "    global X_batch,Y_batch\n",
    "\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_len = len(X_batch)\n",
    "    for ep in range(epoch):\n",
    "        print(\"epoch:{}\".format(ep))\n",
    "        for iter in range(0, batch_len):\n",
    "            input_tensor = X_batch[iter]\n",
    "            target_tensor = Y_batch[iter]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                        decoder, encoder_optimizer, decoder_optimizer, criterion,wd2Idx)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, (iter+1) / batch_len),\n",
    "                                            iter+1, (iter+1) / batch_len * 100, print_loss_avg))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "        print(\"save model seq2seq_attn_bigru in epoch %d\" %(ep))\n",
    "        torch.save(encoder.state_dict(), \"models/seq2seq_attn_bigru/seq2seq_attn_bigru_encoder_epoch_%d.pth\" %(ep))\n",
    "        torch.save(decoder.state_dict(), \"models/seq2seq_attn_bigru/seq2seq_attn_bigru_decoder_epoch_%d.pth\" %(ep))\n",
    "    # showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "vec_dim = 200\n",
    "num_layer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为encoder和decoder加入预训练的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(wd2Idx), hidden_size,vec_dim,num_layer)\n",
    "decoder = Decoder(len(wd2Idx), hidden_size,vec_dim,num_layer,dropout_p=0.1)\n",
    "encoder.embedding.weight.data.copy_(word_vec_net[0].weight.data)\n",
    "decoder.embedding.weight.data.copy_(word_vec_net[0].weight.data)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "0m 0s (- 3m 9s) (1 0%) 0.0504\n",
      "0m 13s (- 0m 52s) (101 20%) 5.1782\n",
      "0m 26s (- 0m 38s) (201 40%) 5.1903\n",
      "0m 39s (- 0m 25s) (301 60%) 5.2746\n",
      "0m 52s (- 0m 12s) (401 80%) 5.2132\n",
      "save model seq2seq_attn_bigru in epoch 0\n",
      "epoch:1\n",
      "1m 5s (- 540m 35s) (1 0%) 4.9512\n",
      "1m 18s (- 5m 8s) (101 20%) 5.0323\n",
      "1m 32s (- 2m 15s) (201 40%) 5.0211\n",
      "1m 45s (- 1m 8s) (301 60%) 5.0575\n",
      "1m 58s (- 0m 28s) (401 80%) 5.0284\n",
      "save model seq2seq_attn_bigru in epoch 1\n",
      "epoch:2\n",
      "2m 11s (- 1080m 59s) (1 0%) 4.8011\n",
      "2m 24s (- 9m 23s) (101 20%) 4.9276\n",
      "2m 37s (- 3m 50s) (201 40%) 4.9124\n",
      "2m 50s (- 1m 50s) (301 60%) 4.9503\n",
      "3m 3s (- 0m 43s) (401 80%) 4.9265\n",
      "save model seq2seq_attn_bigru in epoch 2\n",
      "epoch:3\n",
      "3m 16s (- 1623m 13s) (1 0%) 4.7639\n",
      "3m 29s (- 13m 41s) (101 20%) 4.8979\n",
      "3m 43s (- 5m 27s) (201 40%) 4.8629\n",
      "3m 56s (- 2m 33s) (301 60%) 4.8718\n",
      "4m 10s (- 0m 59s) (401 80%) 4.8477\n",
      "save model seq2seq_attn_bigru in epoch 3\n",
      "epoch:4\n",
      "4m 23s (- 2174m 32s) (1 0%) 4.6453\n",
      "4m 36s (- 18m 2s) (101 20%) 4.8094\n",
      "4m 49s (- 7m 5s) (201 40%) 4.7872\n",
      "5m 3s (- 3m 16s) (301 60%) 4.8050\n",
      "5m 16s (- 1m 15s) (401 80%) 4.8110\n",
      "save model seq2seq_attn_bigru in epoch 4\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder, decoder,wd2Idx,5,print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder,input_tensor,wd2Idx,idx2Wd):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        input_tensor:1,seq_len\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        input_tensor = input_tensor.permute(1,0).contiguous() # seq_len,1\n",
    "        input_length = input_tensor.size()[0]\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(1)\n",
    "        encoder_outputs = torch.zeros(LEN+1,encoder.hidden_size, device=device)\n",
    "        encoder_outputs,encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "        decoder_input = torch.tensor([wd2Idx[\"<S>\"]], device=device).view(1,-1)  # <S>\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        # decoder_attentions = torch.zeros(encode_seq_len, encode_seq_len)\n",
    "\n",
    "        for di in range(4 * LEN):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == wd2Idx[\"<E>\"]:\n",
    "                decoded_words.append('<E>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(idx2Wd[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach().view(1,-1)\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8])\n",
      "晴日东山饱看花\n",
      "春风吹落柳花开\n",
      "春风吹散吹箫鼓\n",
      "不似江南一片花\n"
     ]
    }
   ],
   "source": [
    "input_tensor = X_batch[3][0].view(1,-1)\n",
    "print(input_tensor.size())\n",
    "encoded_words = [idx2Wd[idx.item()] for idx in input_tensor[0]]\n",
    "decoded_words = evaluate(encoder,decoder,input_tensor,wd2Idx,idx2Wd)\n",
    "print(\"\".join(encoded_words[1:]))\n",
    "for i in range(len(decoded_words[:-1])):\n",
    "    print(decoded_words[i],end=\"\")\n",
    "    if (i+1)%7 == 0:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load(\"models/seq2seq_attn_bigru/seq2seq_attn_bigru_encoder_epoch_4.pth\",map_location=torch.device('cpu')))\n",
    "decoder.load_state_dict(torch.load(\"models/seq2seq_attn_bigru/seq2seq_attn_bigru_decoder_epoch_4.pth\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
