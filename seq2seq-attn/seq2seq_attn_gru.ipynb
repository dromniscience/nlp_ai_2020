{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\n在pytorch tutorial的某个例子的基础上作了改动，可以运行，可以作为参考\\n暂时还是用的例子里面的gru和attention方式,已经实现了bidirectional\\n正在尝试改为LSTM\\n'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "\"\"\"\n",
    "在pytorch tutorial的某个例子的基础上作了改动，可以运行，可以作为参考\n",
    "暂时还是用的例子里面的gru和attention方式,已经实现了bidirectional\n",
    "正在尝试改为LSTM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 包导入与常量定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import numpy \n",
    "import time\n",
    "import math\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\n"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./rnnpg_data_emnlp-2014/partitions_in_Table_2/rnnpg/\"  #到数据集的路径，可能根据具体情况修改\n",
    "BATCH_SIZE=128\n",
    "LEN = 7 # 用于决定5言还是7言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "11274 63535\n5260 6742\n11274 63535\n"
    }
   ],
   "source": [
    "def get_train_data(fileName):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        fileName:文件名，具体应该为\"qtrain\"\n",
    "\n",
    "    @return:\n",
    "        poem_line_lst5:五言绝句列表\n",
    "        poem_line_lst7:七言绝句列表\n",
    "        wd2Idx5:适用于五言绝句的wd2Idx映射\n",
    "        wd2Idx7:适用于七言绝句的wd2Idx映射\n",
    "        idx2Wd5:适用于五言绝句的idx2Wd映射\n",
    "        idx2Wd7:适用于七言绝句的idx2Wd映射\n",
    "        poem_vec_lst5:映射后的五言绝句列表\n",
    "        poem_vec_lst7:映射后的七言绝句列表\n",
    "    \n",
    "    其它:\n",
    "        暂时没有为每句诗加上<S>和<E>\n",
    "    \"\"\"\n",
    "    poem_line_lst5 = []\n",
    "    poem_line_lst7 = []\n",
    "\n",
    "    poem_vec_lst5 = []\n",
    "    poem_vec_lst7 = []\n",
    "\n",
    "    vocab5 = []\n",
    "    vocab7 = []\n",
    "\n",
    "    with open(root_path + fileName, 'r', encoding='utf-8') as fin:\n",
    "        for line in fin:\n",
    "            line = (\" \".join(line.strip().split(\"\\t\"))).split(\" \")\n",
    "            line = [\"<S>\"] + line + [\"<E>\"]\n",
    "            if len(line) == 22:\n",
    "                poem_line_lst5.append(line)\n",
    "                vocab5.extend(line)\n",
    "            elif len(line) == 30:\n",
    "                poem_line_lst7.append(line)\n",
    "                vocab7.extend(line)\n",
    "\n",
    "    vocab5 = list(set(vocab5))\n",
    "    vocab7 = list(set(vocab7))\n",
    "    \n",
    "    random.shuffle(poem_line_lst5)\n",
    "    random.shuffle(poem_line_lst7)\n",
    "\n",
    "    wd2Idx5 = {wd: idx for idx, wd in enumerate(vocab5)}\n",
    "    wd2Idx7 = {wd: idx for idx, wd in enumerate(vocab7)}\n",
    "\n",
    "    idx2Wd5 = {idx: wd for idx, wd in enumerate(vocab5)}\n",
    "    idx2Wd7 = {idx: wd for idx, wd in enumerate(vocab7)}\n",
    "\n",
    "    poem_vec_lst5 = [[wd2Idx5[wd] for wd in line] for line in poem_line_lst5]\n",
    "    poem_vec_lst7 = [[wd2Idx7[wd] for wd in line] for line in poem_line_lst7]\n",
    "\n",
    "    print(len(poem_line_lst5), len(poem_line_lst7))\n",
    "    print(len(wd2Idx5), len(wd2Idx7))\n",
    "    print(len(poem_vec_lst5), len(poem_vec_lst7))\n",
    "\n",
    "    return poem_line_lst5, poem_line_lst7, wd2Idx5, wd2Idx7, idx2Wd5, idx2Wd7,poem_vec_lst5, poem_vec_lst7\n",
    "\n",
    "\n",
    "poem_line_lst5, poem_line_lst7, wd2Idx5, wd2Idx7, idx2Wd5, idx2Wd7, poem_vec_lst5, poem_vec_lst7 = get_train_data( \n",
    "    \"qtrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data,bat,sent_len):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        data:待划分的数据集\n",
    "        bat:BATCH_SIZE\n",
    "        sent_len:单句长度\n",
    "    \n",
    "    @returns:\n",
    "        X_batch:shape: len(data)//bat,bat,seq_len,其中seq_len包含四句诗\n",
    "        Y_batch:shape: len(data)//bat,bat,seq_len,其中seq_len包含后三句诗\n",
    "    \"\"\"\n",
    "    X_batch = []\n",
    "    Y_batch = []\n",
    "    for idx in range(len(data)//bat):\n",
    "        st = idx * bat\n",
    "        ed = st + bat\n",
    "        X_batch.append([vec[:sent_len] for vec in data[st:ed]])\n",
    "        Y_batch.append([vec[sent_len:] for vec in data[st:ed]])\n",
    "    X_batch = torch.tensor(X_batch,device=device)\n",
    "    Y_batch = torch.tensor(Y_batch,device=device)\n",
    "    \n",
    "    return X_batch,Y_batch\n",
    "\n",
    "X_batch,Y_batch = get_batch(poem_vec_lst7,BATCH_SIZE,LEN+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([496, 128, 8])\n496\n"
    }
   ],
   "source": [
    "print(X_batch.shape)\n",
    "print(X_batch.size(0))\n",
    "# print(X_batch[0].permute(1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,vec_dim,num_layer):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vec_dim = vec_dim\n",
    "        self.embedding = nn.Embedding(input_size,vec_dim)\n",
    "        self.gru = nn.GRU(vec_dim,hidden_size,bidirectional=True)\n",
    "        self.num_layer = num_layer\n",
    "        self.num_dir = 1 if self.gru.bidirectional == False else 2\n",
    "\n",
    "    def forward(self,input,hidden):\n",
    "        \"\"\"\n",
    "        @params:\n",
    "            input:(seq_len,batch)\n",
    "            hidden:(num_layers*num_dirs,batch,hidden_size)\n",
    "        \"\"\"\n",
    "        seq_len,batch = input.size()\n",
    "\n",
    "        embedded = self.embedding(input).view(seq_len,batch,-1) \n",
    "        output = embedded  # output:(seq_len,batch,vec_dim)\n",
    "        output,hidden = self.gru(output,hidden) # output:(seq_len,batch,num_dir*hidden_size)\n",
    "                                                # hidden:(num_layer*num_dir,batch,hidden_size)\n",
    "        output = output[:,:,:self.hidden_size]+output[:,:,self.hidden_size:]\n",
    "        hidden = hidden.view(self.num_layer,self.num_dir,batch,self.hidden_size)\n",
    "        hidden = hidden[:,0,:,:] + hidden[:,1,:,:]\n",
    "        # output:seq_len,batch,hidden_size\n",
    "        # hidden:num_layer,batch,hidden_size\n",
    "        return output,hidden\n",
    "\n",
    "    def initHidden(self,bat):\n",
    "        \"\"\"\n",
    "        @params\n",
    "            bat:batch参数\n",
    "        \"\"\"\n",
    "        return torch.zeros(self.num_layer*self.num_dir, bat, self.hidden_size, device=device)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带attention机制的Decoder模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,vec_dim,num_layer,dropout_p):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vec_dim = vec_dim\n",
    "        self.embedding = nn.Embedding(input_size,vec_dim)\n",
    "        self.encode_seq_len = LEN+1\n",
    "        self.dropout_p = dropout_p\n",
    "        self.input_size = input_size\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "        self.gru = nn.GRU(vec_dim,hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.vec_dim,self.encode_seq_len)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+self.vec_dim,self.vec_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.out = nn.Linear(self.hidden_size,self.input_size)\n",
    "    \n",
    "    def forward(self,input,hidden,encoder_outputs):\n",
    "        \"\"\"\n",
    "        @params:\n",
    "            encoder_outputs:encode_seq_len,batch,num_dir*hidden_size\n",
    "            hidden:num_layer*num_dir,batch,hidden_size\n",
    "            input:seq_len,batch\n",
    "        \"\"\"\n",
    "        seq_len,batch = input.size()  # when decoding ,we let seq_len = 1\n",
    "\n",
    "        embedded = self.embedding(input).view(seq_len,batch,-1)\n",
    "        embedded = self.dropout(embedded)      # embedded:1,batch,vec_dim\n",
    "\n",
    "        attn_weights = F.softmax(              # attn_weights:batch,encode_seq_len\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                encoder_outputs.permute(1,0,2).contiguous()) \n",
    "        # so far,shape of attn_applied:batch,1,hidden_size\n",
    "        attn_applied = attn_applied.permute(1,0,2).contiguous()\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        # output:1,batch,vec_dim\n",
    "        output,hidden = self.gru(output,hidden)\n",
    "        # output:1,batch,vec_dim\n",
    "        logits = self.out(output)  # logits:1,batch,input_size\n",
    "        logits = logits.view(-1,self.input_size)\n",
    "        \n",
    "        return logits,hidden,attn_weights\n",
    "    \n",
    "    def initHidden(self,bat):\n",
    "        return torch.zeros(self.num_layer, bat, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor,target_tensor,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion,wd2Idx):\n",
    "    \"\"\"\n",
    "    @params\n",
    "        input_tensor:batch,seq_len\n",
    "    \"\"\"\n",
    "\n",
    "    input_tensor = input_tensor.permute(1,0).contiguous()\n",
    "    target_tensor = target_tensor.permute(1,0).contiguous()\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(input_tensor.size()[1])\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_len = input_tensor.size(0)\n",
    "    target_len = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs =  torch.zeros(LEN+1,encoder.hidden_size,device = device) # 单向、batch=1\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs,encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "    # encoder_outputs:encode_seq_len,batch,num_dir*hidden_size\n",
    "    # encoder_hidden:num_layer*num_dir,batch,hidden_size\n",
    "    \n",
    "    decoder_input = torch.tensor([wd2Idx[\"<S>\"]]*BATCH_SIZE,device=device).view(1,BATCH_SIZE)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Teacher forcing\n",
    "    for di in range(target_len):\n",
    "        decoder_output,decoder_hidden,decoder_attention = decoder(\n",
    "            decoder_input,decoder_hidden,encoder_outputs\n",
    "        )\n",
    "        loss += criterion(decoder_output,target_tensor[di])\n",
    "        decoder_input = target_tensor[di].view(1,-1)\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()/target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainIters 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, wd2Idx,epoch,print_every=100, plot_every=100, learning_rate=0.005):\n",
    "\n",
    "    global X_batch,Y_batch\n",
    "\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_len = len(X_batch)\n",
    "    for ep in range(epoch):\n",
    "        print(\"epoch:{}\".format(ep))\n",
    "        for iter in range(0, batch_len):\n",
    "            input_tensor = X_batch[iter]\n",
    "            target_tensor = Y_batch[iter]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                        decoder, encoder_optimizer, decoder_optimizer, criterion,wd2Idx)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, (iter+1) / batch_len),\n",
    "                                            iter+1, (iter+1) / batch_len * 100, print_loss_avg))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "    # showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "vec_dim = 200\n",
    "num_layer = 1\n",
    "encoder = Encoder(len(wd2Idx7), hidden_size,vec_dim,num_layer).to(device)\n",
    "decoder = Decoder(len(wd2Idx7), hidden_size,vec_dim,num_layer,dropout_p=0.1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:0\n0m 3s (- 26m 17s) (1 0%) 1.7628\n0m 4s (- 6m 15s) (6 1%) 7.6173\n0m 6s (- 4m 25s) (11 2%) 7.1021\n0m 7s (- 3m 42s) (16 3%) 7.1024\n0m 8s (- 3m 19s) (21 4%) 7.0840\n0m 10s (- 3m 4s) (26 5%) 7.0463\n0m 11s (- 2m 54s) (31 6%) 7.0565\n0m 13s (- 2m 46s) (36 7%) 7.0402\n0m 14s (- 2m 40s) (41 8%) 6.9753\n0m 15s (- 2m 35s) (46 9%) 6.9334\n0m 17s (- 2m 31s) (51 10%) 6.9024\n0m 18s (- 2m 27s) (56 11%) 6.9468\n0m 20s (- 2m 23s) (61 12%) 6.9320\n0m 21s (- 2m 19s) (66 13%) 6.9068\n0m 22s (- 2m 16s) (71 14%) 6.8750\n0m 24s (- 2m 14s) (76 15%) 6.8342\n0m 25s (- 2m 11s) (81 16%) 6.8288\n0m 26s (- 2m 8s) (86 17%) 6.8010\n0m 28s (- 2m 6s) (91 18%) 6.7568\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-25c1229490eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwd2Idx7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-1eee6a24ccfa>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, wd2Idx, epoch, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             loss = train(input_tensor, target_tensor, encoder,\n\u001b[1;32m---> 22\u001b[1;33m                         decoder, encoder_optimizer, decoder_optimizer, criterion,wd2Idx)\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-93bf9ebc32f9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, wd2Idx)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainIters(encoder, decoder,wd2Idx7,10,print_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder,input_tensor,wd2Idx,idx2Wd):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        input_tensor:1,seq_len\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        input_tensor = input_tensor.permute(1,0).contiguous() # seq_len,1\n",
    "        input_length = input_tensor.size()[0]\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(1)\n",
    "        encoder_outputs = torch.zeros(LEN+1,encoder.hidden_size, device=device)\n",
    "        encoder_outputs,encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "        decoder_input = torch.tensor([wd2Idx[\"<S>\"]], device=device).view(1,-1)  # <S>\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        # decoder_attentions = torch.zeros(encode_seq_len, encode_seq_len)\n",
    "\n",
    "        for di in range(4 * LEN):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == wd2Idx[\"<E>\"]:\n",
    "                decoded_words.append('<E>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(idx2Wd[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach().view(1,-1)\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 8])\n晴日东山饱看花\n一片一年不是一\n年不是一年不是\n一年"
    }
   ],
   "source": [
    "input_tensor = X_batch[3][0].view(1,-1)\n",
    "print(input_tensor.size())\n",
    "encoded_words = [idx2Wd7[idx.item()] for idx in input_tensor[0]]\n",
    "decoded_words = evaluate(encoder,decoder,input_tensor,wd2Idx7,idx2Wd7)\n",
    "print(\"\".join(encoded_words[1:]))\n",
    "for i in range(len(decoded_words[:-1])):\n",
    "    print(decoded_words[i],end=\"\")\n",
    "    if (i+1)%7 == 0:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[1, 2, 3],\n         [3, 4, 5]],\n\n        [[1, 2, 5],\n         [6, 7, 8]]])\n"
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3],[3,4,5]],[[1,2,5],[6,7,8]]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a=1\n"
    }
   ],
   "source": [
    "a = 1\n",
    "print(\"a={}\".format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittorchconda37f84125c92148cfb56b1cd9eac2e957",
   "display_name": "Python 3.7.7 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}