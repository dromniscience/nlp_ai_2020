{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\n在pytorch tutorial的某个例子的基础上作了改动，可以运行，可以作为参考\\n暂时还是用的例子里面的attention方式,已经实现了bidirectional LSTM\\n尚未仔细调参，效果待定\\n'"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "\"\"\"\n",
    "在pytorch tutorial的某个例子的基础上作了改动，可以运行，可以作为参考\n",
    "暂时还是用的例子里面的attention方式,已经实现了bidirectional LSTM\n",
    "尚未仔细调参，效果待定\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 包导入与常量定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\n"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./rnnpg_data_emnlp-2014/partitions_in_Table_2/rnnpg/\"  #到数据集的路径，可能根据具体情况修改\n",
    "BATCH_SIZE=128\n",
    "LEN = 7 # 用于决定5言还是7言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "11274 63535\n5260 6742\n11274 63535\n"
    }
   ],
   "source": [
    "def get_train_data(fileName):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        fileName:文件名，具体应该为\"qtrain\"\n",
    "\n",
    "    @return:\n",
    "        poem_line_lst5:五言绝句列表\n",
    "        poem_line_lst7:七言绝句列表\n",
    "        wd2Idx5:适用于五言绝句的wd2Idx映射\n",
    "        wd2Idx7:适用于七言绝句的wd2Idx映射\n",
    "        idx2Wd5:适用于五言绝句的idx2Wd映射\n",
    "        idx2Wd7:适用于七言绝句的idx2Wd映射\n",
    "        poem_vec_lst5:映射后的五言绝句列表\n",
    "        poem_vec_lst7:映射后的七言绝句列表\n",
    "    \n",
    "    其它:\n",
    "        暂时没有为每句诗加上<S>和<E>\n",
    "    \"\"\"\n",
    "    poem_line_lst5 = []\n",
    "    poem_line_lst7 = []\n",
    "\n",
    "    poem_vec_lst5 = []\n",
    "    poem_vec_lst7 = []\n",
    "\n",
    "    vocab5 = []\n",
    "    vocab7 = []\n",
    "\n",
    "    with open(root_path + fileName, 'r', encoding='utf-8') as fin:\n",
    "        for line in fin:\n",
    "            line = (\" \".join(line.strip().split(\"\\t\"))).split(\" \")\n",
    "            line = [\"<S>\"] + line + [\"<E>\"]\n",
    "            if len(line) == 22:\n",
    "                poem_line_lst5.append(line)\n",
    "                vocab5.extend(line)\n",
    "            elif len(line) == 30:\n",
    "                poem_line_lst7.append(line)\n",
    "                vocab7.extend(line)\n",
    "\n",
    "    vocab5 = list(set(vocab5))\n",
    "    vocab7 = list(set(vocab7))\n",
    "    \n",
    "    random.shuffle(poem_line_lst5)\n",
    "    random.shuffle(poem_line_lst7)\n",
    "\n",
    "    wd2Idx5 = {wd: idx for idx, wd in enumerate(vocab5)}\n",
    "    wd2Idx7 = {wd: idx for idx, wd in enumerate(vocab7)}\n",
    "\n",
    "    idx2Wd5 = {idx: wd for idx, wd in enumerate(vocab5)}\n",
    "    idx2Wd7 = {idx: wd for idx, wd in enumerate(vocab7)}\n",
    "\n",
    "    poem_vec_lst5 = [[wd2Idx5[wd] for wd in line] for line in poem_line_lst5]\n",
    "    poem_vec_lst7 = [[wd2Idx7[wd] for wd in line] for line in poem_line_lst7]\n",
    "\n",
    "    print(len(poem_line_lst5), len(poem_line_lst7))\n",
    "    print(len(wd2Idx5), len(wd2Idx7))\n",
    "    print(len(poem_vec_lst5), len(poem_vec_lst7))\n",
    "\n",
    "    return poem_line_lst5, poem_line_lst7, wd2Idx5, wd2Idx7, idx2Wd5, idx2Wd7,poem_vec_lst5, poem_vec_lst7\n",
    "\n",
    "\n",
    "poem_line_lst5, poem_line_lst7, wd2Idx5, wd2Idx7, idx2Wd5, idx2Wd7, poem_vec_lst5, poem_vec_lst7 = get_train_data( \n",
    "    \"qtrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data,bat,sent_len):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        data:待划分的数据集\n",
    "        bat:BATCH_SIZE\n",
    "        sent_len:单句长度\n",
    "    \n",
    "    @returns:\n",
    "        X_batch:shape: len(data)//bat,bat,seq_len,其中seq_len包含四句诗\n",
    "        Y_batch:shape: len(data)//bat,bat,seq_len,其中seq_len包含后三句诗\n",
    "    \"\"\"\n",
    "    X_batch = []\n",
    "    Y_batch = []\n",
    "    for idx in range(len(data)//bat):\n",
    "        st = idx * bat\n",
    "        ed = st + bat\n",
    "        X_batch.append([vec[:sent_len] for vec in data[st:ed]])\n",
    "        Y_batch.append([vec[sent_len:] for vec in data[st:ed]])\n",
    "    X_batch = torch.tensor(X_batch,device=device)\n",
    "    Y_batch = torch.tensor(Y_batch,device=device)\n",
    "    \n",
    "    return X_batch,Y_batch\n",
    "\n",
    "X_batch,Y_batch = get_batch(poem_vec_lst7,BATCH_SIZE,LEN+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([496, 128, 8])\n496\n"
    }
   ],
   "source": [
    "print(X_batch.shape)\n",
    "print(X_batch.size(0))\n",
    "# print(X_batch[0].permute(1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,vec_dim,num_layer):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vec_dim = vec_dim\n",
    "        self.embedding = nn.Embedding(input_size,vec_dim)\n",
    "        self.lstm = nn.LSTM(vec_dim,hidden_size,num_layers=num_layer,bidirectional=True)\n",
    "        self.num_layer = num_layer\n",
    "        self.num_dir = 1 if self.lstm.bidirectional == False else 2\n",
    "\n",
    "    def forward(self,input,hidden):\n",
    "        \"\"\"\n",
    "        @params:\n",
    "            input:(seq_len,batch)\n",
    "            hidden=(hn,cn):(num_layers*num_dirs,batch,hidden_size)*2\n",
    "        \"\"\"\n",
    "        seq_len,batch = input.size()\n",
    "\n",
    "        embedded = self.embedding(input).view(seq_len,batch,-1) \n",
    "        output = embedded  # output:(seq_len,batch,vec_dim)\n",
    "        output,hidden = self.lstm(output,hidden) # output:(seq_len,batch,num_dir*hidden_size)\n",
    "                                                # hidden:(num_layer*num_dir,batch,hidden_size)*2\n",
    "        output = output[:,:,:self.hidden_size]+output[:,:,self.hidden_size:]\n",
    "        hn,cn = hidden\n",
    "        hn = hn.view(self.num_layer,self.num_dir,batch,self.hidden_size)\n",
    "        hn = hn[:,0,:,:] + hn[:,1,:,:]\n",
    "\n",
    "        cn = cn.view(self.num_layer,self.num_dir,batch,self.hidden_size)\n",
    "        cn = cn[:,0,:,:] + cn[:,1,:,:]\n",
    "        # output:seq_len,batch,hidden_size\n",
    "        # hidden=(hc,cn):(num_layer,batch,hidden_size)*2\n",
    "        return output,(hn,cn)\n",
    "\n",
    "    def initHidden(self,bat):\n",
    "        \"\"\"\n",
    "        @params\n",
    "            bat:batch参数\n",
    "        \"\"\"\n",
    "        h0 = torch.zeros(self.num_layer*self.num_dir, bat, self.hidden_size, device=device)\n",
    "        c0 = torch.zeros(self.num_layer*self.num_dir, bat, self.hidden_size, device=device)\n",
    "        return (h0,c0) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带attention机制的Decoder模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,vec_dim,num_layer,dropout_p):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vec_dim = vec_dim\n",
    "        self.embedding = nn.Embedding(input_size,vec_dim)\n",
    "        self.encode_seq_len = LEN+1\n",
    "        self.dropout_p = dropout_p\n",
    "        self.input_size = input_size\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "        self.lstm = nn.LSTM(vec_dim,hidden_size,num_layers=num_layer,bidirectional=False)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.vec_dim,self.encode_seq_len)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+self.vec_dim,self.vec_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.out = nn.Linear(self.hidden_size,self.input_size)\n",
    "\n",
    "        self.num_dir = 1 if self.lstm.bidirectional == False else 2\n",
    "\n",
    "    def forward(self,input,hidden,encoder_outputs):\n",
    "        \"\"\"\n",
    "        @params:\n",
    "            encoder_outputs:encode_seq_len,batch,num_dir*hidden_size\n",
    "            hidden=(hc,cn):(num_layer*num_dir,batch,hidden_size)*2\n",
    "            input:seq_len,batch\n",
    "        \"\"\"\n",
    "        seq_len,batch = input.size()  # when decoding ,we let seq_len = 1\n",
    "\n",
    "        embedded = self.embedding(input).view(seq_len,batch,-1)\n",
    "        embedded = self.dropout(embedded)      # embedded:1,batch,vec_dim\n",
    "\n",
    "        attn_weights = F.softmax(              # attn_weights:batch,encode_seq_len\n",
    "            self.attn(torch.cat((embedded[0], hidden[0][0]), 1)), dim=1) \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                encoder_outputs.permute(1,0,2).contiguous()) \n",
    "        # so far,shape of attn_applied:batch,1,hidden_size\n",
    "        attn_applied = attn_applied.permute(1,0,2).contiguous()\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        # output:1,batch,vec_dim\n",
    "        output,hidden = self.lstm(output,hidden)\n",
    "        # output:1,batch,vec_dim\n",
    "        logits = self.out(output)  # logits:1,batch,input_size\n",
    "        logits = logits.view(-1,self.input_size) #logits:(-1,input_size)\n",
    "        \n",
    "        return logits,hidden,attn_weights\n",
    "    \n",
    "    def initHidden(self,bat):\n",
    "        h0 = torch.zeros(self.num_dir * self.num_layer, bat, self.hidden_size, device=device)\n",
    "        c0 = torch.zeros(self.num_dir * self.num_layer, bat, self.hidden_size, device=device)\n",
    "        return (h0,c0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor,target_tensor,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion,wd2Idx):\n",
    "    \"\"\"\n",
    "    @params\n",
    "        input_tensor:batch,seq_len\n",
    "    \"\"\"\n",
    "\n",
    "    input_tensor = input_tensor.permute(1,0).contiguous()\n",
    "    target_tensor = target_tensor.permute(1,0).contiguous()\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(input_tensor.size()[1])\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_len = input_tensor.size(0)\n",
    "    target_len = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs =  torch.zeros(LEN+1,encoder.hidden_size,device = device) # 单向、batch=1\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs,encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "    # encoder_outputs:encode_seq_len,batch,num_dir*hidden_size\n",
    "    # encoder_hidden:num_layer*num_dir,batch,hidden_size\n",
    "    \n",
    "    decoder_input = torch.tensor([wd2Idx[\"<S>\"]]*BATCH_SIZE,device=device).view(1,BATCH_SIZE)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Teacher forcing\n",
    "    for di in range(target_len):\n",
    "        decoder_output,decoder_hidden,decoder_attention = decoder(\n",
    "            decoder_input,decoder_hidden,encoder_outputs\n",
    "        )\n",
    "        loss += criterion(decoder_output,target_tensor[di])\n",
    "        decoder_input = target_tensor[di].view(1,-1)\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()/target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainIters 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, wd2Idx,epoch,print_every=100, plot_every=100, learning_rate=0.01):\n",
    "\n",
    "    global X_batch,Y_batch\n",
    "\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_len = len(X_batch)\n",
    "    for ep in range(epoch):\n",
    "        print(\"epoch:{}\".format(ep))\n",
    "        for iter in range(0, batch_len):\n",
    "            input_tensor = X_batch[iter]\n",
    "            target_tensor = Y_batch[iter]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                        decoder, encoder_optimizer, decoder_optimizer, criterion,wd2Idx)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, (iter+1) / batch_len),\n",
    "                                            iter+1, (iter+1) / batch_len * 100, print_loss_avg))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "    # showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "vec_dim = 200\n",
    "num_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(wd2Idx7), hidden_size,vec_dim,num_layer).to(device)\n",
    "decoder = Decoder(len(wd2Idx7), hidden_size,vec_dim,num_layer,dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:0\n0m 0s (- 2m 14s) (1 0%) 1.7638\n0m 1s (- 2m 26s) (6 1%) 7.5657\n0m 3s (- 2m 24s) (11 2%) 7.1505\n0m 4s (- 2m 22s) (16 3%) 7.0559\n0m 6s (- 2m 20s) (21 4%) 6.9869\n0m 7s (- 2m 19s) (26 5%) 6.9128\n0m 9s (- 2m 17s) (31 6%) 6.8822\n0m 10s (- 2m 15s) (36 7%) 6.8506\n0m 11s (- 2m 13s) (41 8%) 6.8084\n0m 13s (- 2m 11s) (46 9%) 6.7811\n0m 14s (- 2m 9s) (51 10%) 6.7550\n0m 16s (- 2m 7s) (56 11%) 6.8223\n0m 17s (- 2m 6s) (61 12%) 6.7848\n0m 19s (- 2m 4s) (66 13%) 6.7626\n0m 20s (- 2m 2s) (71 14%) 6.7480\n0m 21s (- 2m 1s) (76 15%) 6.7182\n0m 23s (- 1m 59s) (81 16%) 6.7333\n0m 24s (- 1m 57s) (86 17%) 6.7087\n0m 26s (- 1m 56s) (91 18%) 6.6663\n0m 27s (- 1m 55s) (96 19%) 6.6634\n0m 29s (- 1m 53s) (101 20%) 6.6681\n0m 30s (- 1m 52s) (106 21%) 6.6412\n0m 31s (- 1m 50s) (111 22%) 6.5857\n0m 33s (- 1m 49s) (116 23%) 6.5706\n0m 34s (- 1m 47s) (121 24%) 6.5818\n0m 36s (- 1m 46s) (126 25%) 6.6142\n0m 37s (- 1m 44s) (131 26%) 6.5296\n0m 38s (- 1m 43s) (136 27%) 6.5576\n0m 40s (- 1m 41s) (141 28%) 6.5234\n0m 41s (- 1m 40s) (146 29%) 6.4479\n0m 43s (- 1m 38s) (151 30%) 6.4462\n0m 44s (- 1m 37s) (156 31%) 6.4686\n0m 46s (- 1m 35s) (161 32%) 6.4091\n0m 47s (- 1m 34s) (166 33%) 6.3944\n0m 48s (- 1m 32s) (171 34%) 6.3800\n0m 50s (- 1m 31s) (176 35%) 6.3414\n0m 51s (- 1m 29s) (181 36%) 6.2398\n0m 53s (- 1m 28s) (186 37%) 6.2684\n0m 54s (- 1m 27s) (191 38%) 6.2321\n0m 55s (- 1m 25s) (196 39%) 6.1900\n0m 57s (- 1m 24s) (201 40%) 6.1576\n0m 58s (- 1m 22s) (206 41%) 6.1151\n1m 0s (- 1m 21s) (211 42%) 6.1116\n1m 1s (- 1m 19s) (216 43%) 6.0743\n1m 2s (- 1m 18s) (221 44%) 6.1078\n1m 4s (- 1m 16s) (226 45%) 6.1008\n1m 5s (- 1m 15s) (231 46%) 6.0650\n1m 7s (- 1m 14s) (236 47%) 6.0871\n1m 8s (- 1m 12s) (241 48%) 6.0397\n1m 10s (- 1m 11s) (246 49%) 5.9950\n1m 11s (- 1m 9s) (251 50%) 6.0193\n1m 12s (- 1m 8s) (256 51%) 6.0282\n1m 14s (- 1m 6s) (261 52%) 5.9555\n1m 15s (- 1m 5s) (266 53%) 5.9923\n1m 17s (- 1m 4s) (271 54%) 5.9518\n1m 18s (- 1m 2s) (276 55%) 5.9412\n1m 19s (- 1m 1s) (281 56%) 5.8666\n1m 21s (- 0m 59s) (286 57%) 5.9122\n1m 22s (- 0m 58s) (291 58%) 5.8980\n1m 24s (- 0m 56s) (296 59%) 5.9115\n1m 25s (- 0m 55s) (301 60%) 5.8648\n1m 27s (- 0m 54s) (306 61%) 5.8454\n1m 28s (- 0m 52s) (311 62%) 5.8665\n1m 29s (- 0m 51s) (316 63%) 5.8807\n1m 31s (- 0m 49s) (321 64%) 5.8726\n1m 32s (- 0m 48s) (326 65%) 5.8548\n1m 34s (- 0m 46s) (331 66%) 5.8371\n1m 35s (- 0m 45s) (336 67%) 5.8053\n1m 37s (- 0m 44s) (341 68%) 5.7843\n1m 38s (- 0m 42s) (346 69%) 5.7599\n1m 39s (- 0m 41s) (351 70%) 5.8118\n1m 41s (- 0m 39s) (356 71%) 5.7612\n1m 42s (- 0m 38s) (361 72%) 5.7684\n1m 44s (- 0m 36s) (366 73%) 5.8164\n1m 45s (- 0m 35s) (371 74%) 5.7458\n1m 46s (- 0m 34s) (376 75%) 5.7788\n1m 48s (- 0m 32s) (381 76%) 5.7437\n1m 49s (- 0m 31s) (386 77%) 5.7275\n1m 51s (- 0m 29s) (391 78%) 5.7581\n1m 52s (- 0m 28s) (396 79%) 5.7268\n1m 54s (- 0m 27s) (401 80%) 5.7408\n1m 55s (- 0m 25s) (406 81%) 5.7260\n1m 57s (- 0m 24s) (411 82%) 5.7200\n1m 58s (- 0m 22s) (416 83%) 5.6972\n1m 59s (- 0m 21s) (421 84%) 5.7187\n2m 1s (- 0m 19s) (426 85%) 5.7030\n2m 2s (- 0m 18s) (431 86%) 5.6971\n2m 4s (- 0m 17s) (436 87%) 5.6963\n2m 5s (- 0m 15s) (441 88%) 5.6651\n2m 7s (- 0m 14s) (446 89%) 5.6471\n2m 8s (- 0m 12s) (451 90%) 5.6887\n2m 9s (- 0m 11s) (456 91%) 5.6822\n2m 11s (- 0m 9s) (461 92%) 5.6994\n2m 12s (- 0m 8s) (466 93%) 5.6648\n2m 14s (- 0m 7s) (471 94%) 5.6799\n2m 15s (- 0m 5s) (476 95%) 5.6760\n2m 16s (- 0m 4s) (481 96%) 5.6863\n2m 18s (- 0m 2s) (486 97%) 5.6676\n2m 19s (- 0m 1s) (491 98%) 5.6480\n2m 21s (- 0m 0s) (496 100%) 5.6765\nepoch:1\n2m 21s (- 1167m 37s) (1 0%) 1.1132\n2m 22s (- 194m 36s) (6 1%) 5.6867\n2m 24s (- 106m 7s) (11 2%) 5.6287\n2m 25s (- 72m 53s) (16 3%) 5.6455\n2m 27s (- 55m 29s) (21 4%) 5.6455\n2m 28s (- 44m 46s) (26 5%) 5.6241\n2m 30s (- 37m 30s) (31 6%) 5.6311\n2m 31s (- 32m 15s) (36 7%) 5.6273\n2m 32s (- 28m 17s) (41 8%) 5.5916\n2m 34s (- 25m 10s) (46 9%) 5.6269\n2m 35s (- 22m 39s) (51 10%) 5.5743\n2m 37s (- 20m 35s) (56 11%) 5.6716\n2m 38s (- 18m 51s) (61 12%) 5.6294\n2m 40s (- 17m 22s) (66 13%) 5.6406\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-25c1229490eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwd2Idx7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-c5fb6c8fd7be>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, wd2Idx, epoch, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             loss = train(input_tensor, target_tensor, encoder,\n\u001b[1;32m---> 22\u001b[1;33m                         decoder, encoder_optimizer, decoder_optimizer, criterion,wd2Idx)\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-83-93bf9ebc32f9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, wd2Idx)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         decoder_output,decoder_hidden,decoder_attention = decoder(\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         )\n\u001b[0;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-fd7223c326c2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# output:1,batch,vec_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;31m# output:1,batch,vec_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# logits:1,batch,input_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 559\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainIters(encoder, decoder,wd2Idx7,10,print_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate with Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trace:\n",
    "    def __init__(self):\n",
    "        self.poem = [\"<S>\"]\n",
    "        self.hidden = None\n",
    "        self.posb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(encoder,decoder,wd2Idx,idx2Wd,input_tensor):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        input_tensor:(1,seq_len)  已经向量化了\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    input_tensor =  input_tensor.permute(1,0).contiguous()\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(1)\n",
    "    encoder_outputs = torch.zeros(LEN+1,encoder.hidden_size, device=device)\n",
    "    encoder_outputs,encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "\n",
    "    beam = [trace()]\n",
    "    beam[0].hidden = encoder_hidden\n",
    "\n",
    "    k=5\n",
    "    for _ in range(4*LEN):\n",
    "        btmp = []\n",
    "        for tce in beam:\n",
    "            inputs = torch.tensor([wd2Idx[tce.poem[-1]]]).view(1,1).to(device)\n",
    "            outputs,hidden,attention = decoder(inputs,tce.hidden,encoder_outputs)\n",
    "            topk = torch.topk(F.softmax(outputs[0]),k)\n",
    "            for i in range(k):\n",
    "                nxt = trace()\n",
    "                nxt.poem = tce.poem+[idx2Wd[topk[1][i].item()]]\n",
    "                nxt.hidden = hidden\n",
    "                nxt.posb = tce.posb + np.log(topk[0][i].item())\n",
    "                btmp.append(nxt)\n",
    "        beam = []\n",
    "        for _ in range(k):\n",
    "            posMax = -1e6\n",
    "            idxMax = 0\n",
    "            for idx,tce in enumerate(btmp):\n",
    "                if tce.posb - posMax > 1e-6:\n",
    "                    posMax = tce.posb\n",
    "                    idxMax = idx\n",
    "            beam.append(btmp[idxMax])\n",
    "            btmp.remove(btmp[idxMax])\n",
    "        \n",
    "    return beam\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = X_batch[3][0].view(1,-1)\n",
    "beam_res = generate(encoder,decoder,wd2Idx7,idx2Wd7,input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No.0\n晴日东山饱看花\n不知何处有人家\n不知此地无消息\n只有春风一夜来\n\nposb: -49.7628253349643\nNo.1\n晴日东山饱看花\n不知何处有人家\n不知此地无消息\n只有春风一片云\n\nposb: -49.870424454870495\nNo.2\n晴日东山饱看花\n不知何处有人家\n不知此地无消息\n只有春风一片花\n\nposb: -50.053576593636784\nNo.3\n晴日东山饱看花\n不知何处有人家\n不知此地无消息\n只有春风不肯知\n\nposb: -50.059569612965994\nNo.4\n晴日东山饱看花\n不知何处有人家\n不知此地无消息\n只有人间不肯知\n\nposb: -50.40054312784527\n"
    }
   ],
   "source": [
    "encoded_words = [idx2Wd7[idx.item()] for idx in input_tensor[0]]\n",
    "for idx,each in enumerate(beam_res):\n",
    "    print(\"No.\",idx,sep=\"\")\n",
    "    poem_lst = each.poem\n",
    "    poem_lst = poem_lst[1:poem_lst.index(\"<E>\")]\n",
    "    print(\"\".join(encoded_words[1:]))\n",
    "    for i in range(len(poem_lst)):\n",
    "        print(poem_lst[i],end=\"\")\n",
    "        if (i+1)%7 == 0:\n",
    "            print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"posb:\",each.posb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[1, 2, 3],\n         [3, 4, 5]],\n\n        [[1, 2, 5],\n         [6, 7, 8]]])\n"
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3],[3,4,5]],[[1,2,5],[6,7,8]]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a=1\n"
    }
   ],
   "source": [
    "a = 1\n",
    "print(\"a={}\".format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittorchconda37f84125c92148cfb56b1cd9eac2e957",
   "display_name": "Python 3.7.7 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}