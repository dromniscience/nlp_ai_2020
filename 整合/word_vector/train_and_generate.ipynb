{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import random\n",
    "from sample import Sample\n",
    "from LoadData import get_train_data\n",
    "from LoadData import get_eval_data\n",
    "from MyDataSet import MyDataSet\n",
    "from MyDataSet import collate_func\n",
    "from word_vector_train import SigmoidBinCELoss\n",
    "from word_vector_train import train_word_vector\n",
    "from CSM import CSM\n",
    "import collections\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "random.seed(1)   #设置随机种子\n",
    "\n",
    "BATCH_SIZE=128\n",
    "root_path = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要：首先你要生成好一个word_vocab。然后执行下面的代码读取这个word_vocab。之后每次都用统一的词表，不然会序号混乱。word_vocab就是一个dict。它的key是词，value是index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "wd2Idx = vocab.copy()\n",
    "idx2Wd = {vocab[word] :word for word in vocab.keys() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要：既然你们要加入分隔符，那么也要对分隔符进行采样。所以你要修改LoadData.py文件中的get_train_data函数。把分隔符加进去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取训练集\n",
    "poem_line_lst5, poem_line_lst7, poem_vec_lst5, poem_vec_lst7 = get_train_data( \n",
    "    \"qtrain\", wd2Idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里是对词表等进行简单的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1511\n"
     ]
    }
   ],
   "source": [
    "print(vocab['<S>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<S>\n"
     ]
    }
   ],
   "source": [
    "print(idx2Wd[1511])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6074\n",
      "['<S>', '持', '鹬', '蚌', '谋', '壮', '贪', '蝉', '鹊', '意', '深', '渔', '人', '一', '拱', '手', '弹', '者', '笑', '依', '林', '<E>']\n"
     ]
    }
   ],
   "source": [
    "print(wd2Idx['<E>'])\n",
    "print(poem_line_lst5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行采样\n",
    "poem_sample = Sample(vocab, idx2Wd, wd2Idx, poem_vec_lst5, poem_vec_lst7, max_window_size=3, noise_num=2)\n",
    "centers, all_contexts, noises = poem_sample.get_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1511\n",
      "[2910]\n",
      "<S>\n",
      "持\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(centers[0])\n",
    "print(all_contexts[0])\n",
    "print(idx2Wd[1511]), print(idx2Wd[2910])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把中心词，背景词，噪声词加入预训练词向量的dataset和dataloader中\n",
    "word_vec_data_set = MyDataSet(centers, all_contexts, noises)#把得到的词放到MyDataSet中\n",
    "word_vec_data_iter = torch.utils.data.DataLoader(word_vec_data_set, BATCH_SIZE, shuffle=True, collate_fn=collate_func, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on cuda\n",
      "save model,in epoch 0\n",
      "epoch 0, loss 2.50, time 181.35s\n",
      "save model,in epoch 1\n",
      "epoch 1, loss 0.85, time 213.57s\n",
      "save model,in epoch 2\n",
      "epoch 2, loss 0.65, time 207.84s\n",
      "save model,in epoch 3\n",
      "epoch 3, loss 0.59, time 187.51s\n",
      "save model,in epoch 4\n",
      "epoch 4, loss 0.56, time 181.75s\n",
      "save model,in epoch 5\n",
      "epoch 5, loss 0.55, time 181.72s\n",
      "save model,in epoch 6\n",
      "epoch 6, loss 0.54, time 181.99s\n",
      "save model,in epoch 7\n",
      "epoch 7, loss 0.54, time 183.00s\n",
      "save model,in epoch 8\n",
      "epoch 8, loss 0.53, time 181.81s\n",
      "save model,in epoch 9\n",
      "epoch 9, loss 0.53, time 181.69s\n"
     ]
    }
   ],
   "source": [
    "#开始进行预训练词向量\n",
    "\n",
    "embed_size = 200\n",
    "learn_rate = 0.001\n",
    "epochs = 10\n",
    "vocab_size = len(vocab)\n",
    "loss = SigmoidBinCELoss()\n",
    "#构建词词嵌入层，训练其中的词向量\n",
    "word_vec_net = nn.Sequential(nn.Embedding(vocab_size, embed_size),\n",
    "                     nn.Embedding(vocab_size, embed_size))\n",
    "#训练\n",
    "train_word_vector(word_vec_net, word_vec_data_iter, learn_rate, loss, epochs)\n",
    "#训练完成后，中心词向量word_vec_net[0]可作为词的表征向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是使用预训练的词向量的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1055, -0.1768,  0.9093,  ..., -0.5408,  0.1471,  0.0205],\n",
       "        [ 0.6076,  0.9130, -0.2320,  ..., -1.0624, -0.2578, -1.1538],\n",
       "        [-2.3329,  0.1328,  0.3395,  ...,  0.3982,  1.4768,  0.0994],\n",
       "        ...,\n",
       "        [-0.1787, -0.3751, -0.1778,  ...,  2.7739, -0.5851, -0.5034],\n",
       "        [-1.1934, -1.7688, -1.6601,  ...,  0.3613, -1.2547, -2.8550],\n",
       "        [-1.1588,  1.3626,  0.4672,  ...,  0.1904,  0.0054, -0.8986]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #首先，读取已保存好的模型参数\n",
    "word_vec_net.load_state_dict(torch.load('net_epoch_9.pth'))\n",
    "\n",
    "#这是使用预训练词向量的demo\n",
    "#使用预训练的词向量。例如：\n",
    "csm = CSM(vocab_size, embed_size, scentence_size=5)\n",
    "csm.embedding.weight.data.copy_(word_vec_net[0].weight.data)#word_vec_net[0]中的数据，就是预训练的词向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_vec_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7f261c81ded4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_similar_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'好'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_vec_net\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd2Idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx2Wd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_vec_net' is not defined"
     ]
    }
   ],
   "source": [
    "get_similar_token('好', 5, word_vec_net[0].weight.data, wd2Idx, idx2Wd)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
